---
title: "Dataset Cleaner/Merger"
output:
  pdf_document: default
  html_document:
    df_print: paged
---

```{r setup, include=FALSE}
knitr::opts_chunk$set(echo = TRUE)
library(plyr)
library(dplyr)
library(janitor)
library(readxl)
library(tidyverse)
```

## Gallup Analytics

The following dataset includes data for 16 questions, observed in 140+  countries in years from 2006 to 2019.

The default output from the Gallup platform is an .xlsx file with a different sheet for each question. Here, I pivot the dataframes and merge all of them into  one.

The formats of the spreadsheets vary, so here, I break up exports into 3 categories of questions by the types of responses, to allow for automated cleaning:

* yes/no:
  + Corruption in Government
  + Corruption Within Businesses
  + Smile or Laugh
  + Feel Well-Rested
  + Experienced Enjoyment Yesterday
  + Experienced Physical Pain Yesterday
  + Experience Worry Yesterday
  + Experience Stress Yesterday
  + Experience Sadness Yesterday
  + Experience Anger Yesterday

* strongly_disagree/somewhat_disagree/neither/somewhat_agree/strongly_agree:
  + Worried About Money
  
* very_likely/somewhat_likely/not_likely_at_all:
  + Likelihood Stranger Would Return a Lost Bag
  + Likelihood Police Would Return a Lost Bag
  + Likelihood Neighbor Would Return Lost Bag

* value:
  + Positive Experience Index
  + Negative Experience Index

First, create functions for cleaning, pivoting variables, and renaming the columns 
in the dataset.

```{r gallup1}
# Read in Excel sheet corresponding to a question

read_gallup <- function(path, question){
  data <- read_excel(path,
                     sheet = question, 
                     skip = 6) %>%
    
    # Make column names simpler
    
    clean_names()
  
  return(data)
}

# Reorder the pivoted columns by year instead of by response type (variable name)

reorder_columns <- function(suffixes, data){
  names_to_order <- map(suffixes, 
                        ~ names(data)[grep(paste0("_", .x), names(data))]) %>% unlist
  
  names_id <- setdiff(names(data), names_to_order)
  
  data <- data %>%
    select(all_of(names_id), all_of(names_to_order))
  
  return(data)
}

# Declare reponse types and corresponding "extra" columns in the spreadsheet 
# to be erased

extra_columns_yes_no = c("demographic", "demographic_value", "dk_rf", "n_size")
response_types_yes_no = c("yes", "no")

extra_columns_likely = c("demographic", "demographic_value", "dk", "refused", 
                         "n_size")
response_types_likely = c("very_likely", "somewhat_likely", "not_likely_at_all")

extra_columns_agree_disagree = c("demographic", "demographic_value", "dk", 
                                 "refused", "n_size")
response_types_agree_disagree = c("strongly_disagree", "somewhat_disagree", 
                                  "neither_agree_nor_disagree", "somewhat_agree", 
                                  "strongly_agree")

extra_columns_value = c("demographic", "demographic_value", "n_size")
response_types_value = "value"

clean_gallup <- function(path, question, prefix, extra_columns, response_types){
  data <- read_gallup(path, question)
  
  # Store years for reordering purposes
  
  suffixes <- unique(data$time)

  # Pivot the dataframe to have different variables by year
  
  data <- data %>%
    select(!all_of(extra_columns)) %>%
    pivot_wider(names_from = time,
                values_from = all_of(response_types))
  
  # Reorder the pivoted columns by year instead of by response type (variable name)
  
  data <- reorder_columns(suffixes, data)
  
  # Add question prefix to column names
  
  data <- data %>% rename_at(2:ncol(.), ~ paste(prefix, ., sep = "_"))
}
```

Second, create dataframes for each of the 16 questions.

```{r gallup2}
corrupt_government <- clean_gallup("input_data/corrupt_government.xlsx", 
                                   "Corruption in Government", 
                                   "corrupt_government", 
                                   extra_columns_yes_no, 
                                   response_types_yes_no)

corrupt_bussinesses <- clean_gallup("input_data/corrupt_bussinesses.xlsx", 
                                    "Corruption Within Businesses", 
                                    "corrupt_bussinesses", 
                                    extra_columns_yes_no, 
                                    response_types_yes_no)

smile_laugh <- clean_gallup("input_data/smile_laugh.xlsx", 
                            "Smile or Laugh", 
                            "smile_laugh", 
                            extra_columns_yes_no, 
                            response_types_yes_no)

rested <- clean_gallup("input_data/rested.xlsx", 
                       "Feel Well-Rested", 
                       "rested", 
                       extra_columns_yes_no, 
                       response_types_yes_no)

enjoyment <- clean_gallup("input_data/enjoyment.xlsx", 
                          "Experienced Enjoyment Yesterday", 
                          "enjoyment", 
                          extra_columns_yes_no, 
                          response_types_yes_no)

physical_pain <- clean_gallup("input_data/physical_pain.xlsx", 
                              "Experienced Physical Pain Yeste", 
                              "physical_pain", 
                              extra_columns_yes_no, 
                              response_types_yes_no)

worry <- clean_gallup("input_data/worry.xlsx", 
                      "Experience Worry Yesterday", 
                      "worry", 
                      extra_columns_yes_no, 
                      response_types_yes_no)

stress <- clean_gallup("input_data/stress.xlsx", 
                       "Experience Stress Yesterday", 
                       "stress", 
                       extra_columns_yes_no, 
                       response_types_yes_no)

sadness <- clean_gallup("input_data/sadness.xlsx", 
                        "Experience Sadness Yesterday", 
                        "sadness", 
                        extra_columns_yes_no, 
                        response_types_yes_no)

anger <- clean_gallup("input_data/anger.xlsx", 
                      "Experience Anger Yesterday", 
                      "anger", 
                      extra_columns_yes_no, 
                      response_types_yes_no)

worry_money <- clean_gallup("input_data/worry_money.xlsx", 
                      "Worried About Money", 
                      "worry_money", 
                      extra_columns_agree_disagree, 
                      response_types_agree_disagree)

stranger_return_bag <- clean_gallup("input_data/stranger_return_bag.xlsx", 
                      "Likelihood Stranger Would Retur", 
                      "stranger_return_bag", 
                      extra_columns_likely, 
                      response_types_likely)

police_return_bag <- clean_gallup("input_data/police_return_bag.xlsx", 
                      "Likelihood Police Would Return ", 
                      "police_return_bag", 
                      extra_columns_likely, 
                      response_types_likely)

neighbor_return_bag <- clean_gallup("input_data/neighbor_return_bag.xlsx", 
                      "Likelihood Neighbor Would Retur", 
                      "neighbor_return_bag", 
                      extra_columns_likely, 
                      response_types_likely)

positive_index <- clean_gallup("input_data/positive_index.xlsx", 
                      "Positive Experience Index", 
                      "positive_index", 
                      extra_columns_value, 
                      response_types_value)

negative_index <- clean_gallup("input_data/negative_index.xlsx", 
                      "Negative Experience Index", 
                      "negative_index", 
                      extra_columns_value, 
                      response_types_value)
```

Finally, merge all response variables into one dataset by country.

```{r gallup3}
# Create a list of dataframes to merge

indicators <- list(
  # yes/no:
  
  corrupt_government, corrupt_bussinesses, smile_laugh, rested, enjoyment, 
  physical_pain, worry, stress, sadness, anger, 
  
  # agree/disagree:
  
  worry_money,
  
  # likely:
  
  stranger_return_bag, police_return_bag, neighbor_return_bag,
  
  # value:
  
  positive_index, negative_index)

# Perform a full_join on all datsets

gallup_data <- join_all(indicators, by = "geography", type = "full")


```


## Empathy (Chopik et al., 2017)
#### Source: https://journals.sagepub.com/doi/abs/10.1177/0022022116673910

The data is presented in a .docx file, which I converted to an .xlsx and then pulled out the 3 variables observed in 63 countries:

* Mean Total Empathy
* Mean Perspective Taking
* Mean Empathic Concern

I changed some of the country names in the resulting .xlsx for consistency with  the Gallup dataset to make merging possible.

Here, I merge them with our existing dataset.

Data was collected before 2016, though I couldn't identify a specific year.


```{r empathy1}
empathy_data <- read_excel("input_data/empathy.xlsx") %>%
  clean_names()

dataset <- full_join(gallup_data, empathy_data, by = "geography")
```

## Global Preferences Survey
#### Source: https://www.briq-institute.org/global-preferences/downloads

I downloaded the dataset, which was presented in the .dta format native to Stata. 

It also uses ISO 3166-1 alpha-3 format for country names, which I'll convert using the package `ISOcodes` for the purpose of merging datasets by full country name.

Convert and merge all variables to our dataset:

Data was collected in 2012

```{r gps1}
library(ISOcodes)

gps_data <- read_excel("input_data/GPS_country.xlsx")

ISO_3166_1_names <- ISO_3166_1 %>%
  select(Alpha_3, Name, Common_name)

# Merge to pair up ISO codes with full country names

gps_data_iso <- left_join(gps_data, ISO_3166_1_names, 
                          by = c("isocode" = "Alpha_3")) 

gps_data <- gps_data_iso %>%
  # Rename isocodes into full country names, using the common name instead 
  # of official if available
  
  mutate(geography = if_else(condition = is.na(Common_name),
                                          Name,
                                          Common_name)) %>%
  
  # Select only the new country name column (geography) and all variables
  
  select(geography, colnames(gps_data_iso)[2:48])
```


```{r gps2}
# Merge with our dataset

dataset_with_gps <- full_join(dataset, gps_data, by = "geography") 

# Check for country rows that did not merge correctly. Some countries might have 
# not beeen in the original dataset, but others might just be named differently, 
# which needs to be fixed.

dataset_with_gps %>%
  filter(!(geography %in% dataset$geography)) %>%
  select(geography)
```

```{r gps3}
# Manually fix country names that did not merge properly by renaming 
# in the original GPS dataset and merging again

gps_data[gps_data == "Czechia"] <- "Czech Republic"
gps_data[gps_data == "Iran, Islamic Republic of"] <- "Iran"
gps_data[gps_data == "Korea, Republic of"] <- "South Korea"
gps_data[gps_data == "Russian Federation"] <- "Russia"
gps_data[gps_data == "United States"] <- "United States of America"

dataset <- full_join(dataset, gps_data, by = "geography") 
```

## Corruption Perceptions Index
#### Source: https://www.transparency.org/en/cpi/

I downloaded a dataset containing time series CPI data for ~180 countries from 2012 to 2019. 

Clean and merge into our dataset:

```{r cpi1}
cpi_data <- read_excel("input_data/CPI2019.xlsx", 
    sheet = "CPI Timeseries 2012 - 2019", 
    skip = 2) %>%
  
  # Only keep CPI scores for each country from 2012 to 2019
  
  clean_names() %>%
  select(country, cpi_score_2012, cpi_score_2013, cpi_score_2014, cpi_score_2015,
         cpi_score_2016, cpi_score_2017, cpi_score_2018, cpi_score_2019)
```

```{r cpi2}
dataset_with_cpi <- full_join(dataset, cpi_data, by = c("geography" = "country")) 

dataset_with_cpi %>%
  filter(!(geography %in% dataset$geography)) %>%
  select(geography)
```
```{r cpi3}
# Manually fix country names that did not merge properly by renaming 
# in the original CPI dataset and merging again

cpi_data[cpi_data == "Korea, South"] <- "South Korea"
cpi_data[cpi_data == "Korea, North"] <- "North Korea"

dataset <- full_join(dataset, cpi_data, by = c("geography" = "country"))
```

##  Returning lost wallets in 40 countries (Cohn et al., 2019).
#### Source: https://dataverse.harvard.edu/dataverse/honesty

Manipulate experiment results to obtain rates (%) of wallet returns in each country by experimental condition:

```{r lost_wallets1}
lost_wallets <- read.csv("input_data/lost_wallets_data.csv")

wallet_return_metrics <- lost_wallets %>%
  select(Country, cond, response) %>%
  group_by(Country, cond) %>%
  summarize(return_percentage = mean(response), .groups = "drop") %>%
  mutate(cond = as.factor(cond)) %>%
  mutate(cond = case_when(cond == 0 ~ "NoMoney",
                          cond == 1 ~ "Money",
                          cond == 2 ~ "BigMoney",
                          cond == 3 ~ "NoKey")) %>%
  pivot_wider(names_from = cond, 
              values_from = return_percentage, 
              names_glue = "{.value}_{cond}") %>%
  rename(geography = Country)
```


```{r lost_wallets2}
# Merge with our dataset
dataset_with_wallet_return <- full_join(dataset, wallet_return_metrics, 
                                        by = "geography") 

# Check for country rows that did not merge correctly. Some countries might have 
# not beeen in the original dataset, but others might just be named differently, 
# which needs to be fixed.

dataset_with_wallet_return %>%
  filter(!(geography %in% dataset$geography)) %>%
  select(geography)
```
```{r lost_wallets3}
# Manually fix country names that did not merge properly by renaming 
# in the original lost wallet dataset and merging again

wallet_return_metrics[wallet_return_metrics == "UAE"] <- "United Arab Emirates"
wallet_return_metrics[wallet_return_metrics == "UK"] <- "United Kingdom"
wallet_return_metrics[wallet_return_metrics == "USA"] <- "United States of America"

dataset <- full_join(dataset, wallet_return_metrics, by = "geography") 
```


Data was collected between 2013 and 2016 depending on the country.

## Moral preferences in sacrificial dilemmas (Awad et al., 2020)
#### Source: https://osf.io/mxa6z/?view_only=33719a32d86a4ec186a21287a233040c

```{r moral_preferences1}
load("input_data/moral_preferences.rdata")

ISO_3166_1_names2 <- ISO_3166_1 %>%
  select(Alpha_2, Name, Common_name)

moral_preference_data_iso <- left_join(ddl, ISO_3166_1_names2, 
                                       by = c("two_letter_code" = "Alpha_2")) 

moral_preference_data <- moral_preference_data_iso %>%
  # Rename isocodes into full country names, using the common name instead of 
  # official if available
  
  mutate(geography = if_else(condition = is.na(Common_name),
                                          Name,
                                          Common_name)) %>%
  
  # Select only the new country name column (geography) and all variables
  
  select(geography, RML:Footbridge)
```


```{r moral_preferences2}
# Merge with our dataset

dataset_with_moral_preference <- full_join(dataset, moral_preference_data, 
                                           by = "geography") 

# Check for country rows that did not merge correctly. Some countries might have 
# not beeen in the original dataset, but others might just be named differently, 
# which needs to be fixed.

dataset_with_moral_preference %>%
  filter(!(geography %in% dataset$geography)) %>%
  select(geography)
```

```{r moral_preferences3}
# Manually fix country names that did not merge properly by renaming 
# in the original moral preference dataset and merging again

moral_preference_data[moral_preference_data == "Czechia"] <- "Czech Republic"
moral_preference_data[moral_preference_data == "Iran, Islamic Republic of"] <- "Iran"
moral_preference_data[moral_preference_data == "Korea, Republic of"] <- "South Korea"
moral_preference_data[moral_preference_data == "Korea, Democratic People's Republic of"] <- "North Korea"
moral_preference_data[moral_preference_data == "Russian Federation"] <- "Russia"
moral_preference_data[moral_preference_data == "United States"] <- "United States of America"

dataset <- full_join(dataset, moral_preference_data, by = "geography") 
```

## Final Result

Write the final merged dataset into a .csv
```{r final}
# Arrange countries in alphabetical order

dataset <- dataset %>%
  rename(country = geography) %>%
  arrange(country)

write_csv(dataset, "output_data/dataset.csv")
```